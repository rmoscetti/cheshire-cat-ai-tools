# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/weave_eval.ipynb.

# %% auto 0
__all__ = ['settings', 'conf_variants', 'hallucination_scorer', 'similarity_scorer', 'remove_think', 'CatModel',
           'load_eval_dataset', 'repeat_dataset', 'CatEmbeddingSimilarityScorer', 'read_sentences',
           'prepare_declarative_memory', 'eval_configs']

# %% ../nbs/weave_eval.ipynb 2
from .client import SuperCatClient, LLMSettings, LLMSetting
from cheshire_cat_api.config import Config
import weave
from typing import Optional, Any
from pyprojroot import here
import pandas as pd
from weave.scorers import HallucinationFreeScorer, EmbeddingSimilarityScorer
from tqdm.auto import tqdm
from datetime import datetime

# %% ../nbs/weave_eval.ipynb 3
settings = LLMSettings()

# %% ../nbs/weave_eval.ipynb 4
conf_variants = {
    "openai_smallest": settings.openai.model_copy(update={"model_name": "gpt-5-nano"}),
    "openai_best": settings.openai.model_copy(update={"model_name": "gpt-5"}),
    "gemini_smallest": settings.gemini.model_copy(
        update={"model": "gemini-2.5-flash-lite"}
    ),
    "gemini_best": settings.gemini.model_copy(update={"model": "gemini-2.5-pro"}),
    "gemma_smallest": settings.ollama.model_copy(update={"model": "gemma3:1b"}),
    "gemma_best": settings.ollama.model_copy(update={"model": "gemma3:27b"}),
    "qwen_smallest": settings.ollama.model_copy(update={"model": "qwen3:0.6b"}),
    "qwen_best": settings.ollama.model_copy(update={"model": "qwen3:32b"}),
    "deepseek_smallest": settings.ollama.model_copy(
        update={"model": "deepseek-r1:1.5b"}
    ),
    "deepseek_best": settings.ollama.model_copy(update={"model": "deepseek-r1:32b"}),
}

# %% ../nbs/weave_eval.ipynb 5
import re

def remove_think(text):
    # Removes everything between <think> and </think>, including the tags
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)

# %% ../nbs/weave_eval.ipynb 6
class CatModel(weave.Model):
    client: SuperCatClient
    has_declarative_memory: bool = True

    def __init__(
        self, model_name: str, llm_setting, has_declarative_memory:bool = True, client_config: Optional[Config] = None
    ):
        super().__init__(
            name=model_name, client=SuperCatClient(config=client_config or Config()), has_declarative_memory=has_declarative_memory
        )
        self.client.udpate_llm_setting(llm_setting.name, llm_setting.model_dump())

    @weave.op()
    async def predict(self, prompt: str) -> dict:
        response = self.client.send(prompt)
        self.client.wipe_episodic_memory()
        response["model_name"] = self.name
        response["text_clean"] = remove_think(response.get("text", ""))
        response['has_declarative_memory'] = self.has_declarative_memory
        return response

# %% ../nbs/weave_eval.ipynb 9
def load_eval_dataset():
    path = here("eval/declarative_memory.csv")
    df = pd.read_csv(path)
    return [
        {
            "id": i,
            "prompt": row["domanda"],
            "input": row["domanda"],
            "context": row["risposta"],
            "target": row["risposta"],
        }
        for i, row in df.iterrows()
    ]


# %% ../nbs/weave_eval.ipynb 10
def repeat_dataset(dataset, n):
    id = 0
    for d in dataset:
        for _ in range(n):
            yield {**d, "id": id, "question_id": d["id"]}
            id += 1
            

# %% ../nbs/weave_eval.ipynb 13
hallucination_scorer = HallucinationFreeScorer(
    model_id="vertex_ai/gemini-2.5-pro",
)


# %% ../nbs/weave_eval.ipynb 14
class CatEmbeddingSimilarityScorer(EmbeddingSimilarityScorer):
    @weave.op
    async def score(self, *, output: str, target: str, **kwargs: Any) -> Any:
        # Ensure the threshold is within the valid range for cosine similarity.
        assert -1 <= self.threshold <= 1, "`threshold` should be between -1 and 1"

        model_embedding, target_embedding = await self._compute_embeddings(
            output["text_clean"], target
        )
        return self._cosine_similarity(model_embedding, target_embedding)


similarity_scorer = CatEmbeddingSimilarityScorer(
    model_id="vertex_ai/gemini-embedding-001",
    threshold=0.8,
)

# %% ../nbs/weave_eval.ipynb 15
def read_sentences():
    path = here("eval/declarative_memory.csv")
    df = pd.read_csv(path)
    return df['risposta'].tolist()

# %% ../nbs/weave_eval.ipynb 16
def prepare_declarative_memory(client: SuperCatClient):
    client.wipe_declarative_memory()
    sentences = read_sentences()
    client.put_sentences(sentences)
    print(f"Added {len(sentences)} sentences to declarative memory")

# %% ../nbs/weave_eval.ipynb 17
async def eval_configs(dataset, n_rep=1, model_confs=conf_variants):
    client = SuperCatClient()
    time = datetime.now().strftime("%m-%d %H:%M")
    eval_name = f"{time} Eval"
    prepare_declarative_memory(client)
    evaluation = weave.Evaluation(
        dataset=list(repeat_dataset(dataset, n_rep)),
        scorers=[similarity_scorer],
        name=eval_name,
    )
    for name, conf in tqdm(model_confs.items(), total=len(model_confs)):
        print(f"Evaluating {name} with memory")
        model = CatModel(name, conf)
        await evaluation.evaluate(model, __weave={"display_name": f"{eval_name} - {name} memory"})
    client.wipe_declarative_memory()
    for name, conf in tqdm(model_confs.items(), total=len(model_confs)):
        print(f"Evaluating {name} without memory")
        model = CatModel(name, conf, has_declarative_memory=False)
        await evaluation.evaluate(model, __weave={"display_name": f"{eval_name} - {name} NO memory"})
