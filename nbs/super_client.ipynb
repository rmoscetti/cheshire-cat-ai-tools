{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from typing import Optional\n",
    "from cheshire_cat_api.config import Config\n",
    "from cheshire_cat_api import CatClient\n",
    "from cheshire_cat_api.models import SettingBody\n",
    "import requests\n",
    "import time\n",
    "from queue import Queue\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class SuperCatClient:\n",
    "    \"\"\"\n",
    "    A Wrapper around the official client for sane handling of the websockets connections\n",
    "\n",
    "    Uses a queue to communite with the websocket thread and blocks until a response is received.\n",
    "    This is needed as there is a bug in the cat that results in tools not being executed if we make a simple POST request\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Optional[Config] = None):\n",
    "        self.cat_client = CatClient(config, on_message=self.on_message)\n",
    "        self.cat_client.connect_ws()\n",
    "        self.wait_for_connection()\n",
    "        self.queue = Queue()\n",
    "\n",
    "        self.host = self.cat_client.memory.api_client.configuration.host\n",
    "\n",
    "    def on_message(self, message):\n",
    "        # this run on the websocket thread\n",
    "        try:\n",
    "            message = json.loads(message)\n",
    "            if message.get(\"type\") == \"chat_token\":\n",
    "                return\n",
    "            self.queue.put(message)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to decode message: {e}\")\n",
    "\n",
    "    def wait_for_connection(self, timeout=10):\n",
    "        start_time = time.time()\n",
    "        while not self.cat_client.is_ws_connected:\n",
    "            time.sleep(1)\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\n",
    "                    f\"Failed to connect to WebSocket within timeout ({timeout} sec).\"\n",
    "                )\n",
    "\n",
    "    def send(self, message):\n",
    "        self.cat_client.send(message)\n",
    "        return self.queue.get(10)\n",
    "\n",
    "    def udpate_setting(self, name, value, category=\"\"):\n",
    "        setting_id = next(\n",
    "            (\n",
    "                s[\"setting_id\"]\n",
    "                for s in requests.get(\n",
    "                    f\"{self.host}/settings/\",\n",
    "                ).json()[\"settings\"]\n",
    "                if s[\"name\"] == name\n",
    "            )\n",
    "        )\n",
    "        r = requests.put(\n",
    "            f\"{self.host}/settings/{setting_id}\",\n",
    "            json={\n",
    "                \"name\": name,\n",
    "                \"value\": value,\n",
    "                'category': category\n",
    "            },\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r \n",
    "    \n",
    "    def udpate_llm_setting(self, llm_name, value):\n",
    "\n",
    "        r = requests.put(\n",
    "            f\"{self.host}/llm/settings/{llm_name}\",\n",
    "            json=value\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "\n",
    "    def delete_episodic_memory(self):\n",
    "        r = requests.delete(f\"{self.host}/memory/conversation_history\")\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # forward all the other calls to the official client\n",
    "        if hasattr(self, \"cat_client\"):\n",
    "            return getattr(self.cat_client, name)\n",
    "\n",
    "    def close(self):\n",
    "        self.cat_client.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.cat_client.close()\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Enter the runtime context related to this object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"Exit the runtime context and clean up resources.\"\"\"\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = SuperCatClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b7373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.udpate_setting(\"llm_selected\", {\"name\": \"LLMOpenAIChatConfig\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdda97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.udpate_llm_setting(\"LLMOpenAIChatConfig\", {\"model\": \"gpt-4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from pydantic import BaseModel, SecretStr\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from typing import ClassVar\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f57842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMSetting(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMOpenAIChatConfig(LLMSetting):\n",
    "    name: ClassVar[str] = \"LLMOpenAIChatConfig\"\n",
    "    openai_api_key: str\n",
    "    model_name: str = \"gpt-5-mini\"\n",
    "    temperature: float = 1.0\n",
    "    streaming: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai_api_key': 'aa',\n",
       " 'model_name': 'gpt-5-mini',\n",
       " 'temperature': 0.5,\n",
       " 'streaming': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLMOpenAIChatConfig(openai_api_key=\"aa\").model_copy(update={\"temperature\": 0.5}).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMOllamaConfig(LLMSetting):\n",
    "    name: ClassVar[str] = \"LLMOllamaConfig\"\n",
    "    base_url: str\n",
    "    model: str = \"llama3\"\n",
    "    num_ctx: int = 2048\n",
    "    repeat_last_n: int = 64\n",
    "    repeat_penalty: float = 1.1\n",
    "    temperature: float = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMGeminiChatConfig(LLMSetting):\n",
    "    name: ClassVar[str] = \"LLMGeminiChatConfig\"\n",
    "    google_api_key: str\n",
    "    model: str = \"gemini-2.5-pro-latest\"\n",
    "    temperature: float = 1.0\n",
    "    top_p: int = 1\n",
    "    top_k: int = 1\n",
    "    max_output_tokens: int = 29000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMSettings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(env_nested_delimiter=\"__\", env_file=here(\".env.local\"))\n",
    "    openai: LLMOpenAIChatConfig\n",
    "    ollama: LLMOllamaConfig\n",
    "    gemini: LLMGeminiChatConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = LLMSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05725ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_settings():\n",
    "    r = requests.get(f\"{client.host}/llm/settings/\")\n",
    "    r.raise_for_status()\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfde75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.udpate_llm_setting(\"LLMOpenAIChatConfig\", {\"model\": \"gpt-5-mini\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de24ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLMOpenAIChatConfig'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_settings()['selected_configuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fd10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.udpate_llm_setting(settings.ollama.name, settings.ollama.model_copy(update={\"model\": \"gemma3:27b\"}).model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42dea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLMOllamaConfig'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_settings()['selected_configuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_llm(settings.ollama.model_copy(update={\"model\": \"gemma3:27b\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings0 = requests.get(f\"{client.host}/settings/\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cbc467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'LLMOllamaConfig',\n",
       "  'value': {'base_url': 'http://192.168.100.134:11444',\n",
       "   'model': 'gemma3:27b',\n",
       "   'num_ctx': 2048,\n",
       "   'repeat_last_n': 64,\n",
       "   'repeat_penalty': 1.1,\n",
       "   'temperature': 1.0},\n",
       "  'category': 'llm_factory',\n",
       "  'setting_id': '588a97f1-6688-4d7f-b42a-9370844a7813',\n",
       "  'updated_at': 1756724055}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in settings0['settings'] if x['name'] == settings.ollama.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'llm_selected',\n",
       "  'value': {'name': 'LLMOllamaConfig'},\n",
       "  'category': 'llm',\n",
       "  'setting_id': 'f8074e79-8a31-4b56-ad4b-5c914f844763',\n",
       "  'updated_at': 1756722764}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in settings0['settings'] if x['name'] == 'llm_selected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings1 = requests.get(f\"{client.host}/settings/\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b28d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'llm_selected',\n",
       "  'value': {'name': 'LLMOpenAIChatConfig'},\n",
       "  'category': 'llm',\n",
       "  'setting_id': 'c677b4e2-71b0-409b-8c2c-c331c3ee7ffa',\n",
       "  'updated_at': 1756723505}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in settings1['settings'] if x['name'] == 'llm_selected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572a19f",
   "metadata": {},
   "source": [
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d5366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
